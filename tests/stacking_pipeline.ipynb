{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8e6ee438",
      "metadata": {
        "id": "8e6ee438"
      },
      "source": [
        "# ğŸ“ Life Expectancy Prediction â€“ Full Pipeline with Stacking Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q catboost tab-transformer-pytorch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvHqqScLfVwF",
        "outputId": "030815e8-a383-43e2-a22c-b823a0845cc3"
      },
      "id": "TvHqqScLfVwF",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f094c007",
      "metadata": {
        "id": "f094c007"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import ElasticNet, LinearRegression\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "from catboost import CatBoostRegressor\n",
        "from tab_transformer_pytorch import TabTransformer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "149da9ce",
      "metadata": {
        "id": "149da9ce"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "df = pd.read_csv(\"modified.csv\")\n",
        "\n",
        "# Column setup\n",
        "target = 'Life expectancy'\n",
        "categorical_cols = ['Gender']\n",
        "ignore_cols = ['Country', 'Year', 'Year.1', target]\n",
        "numerical_cols = [col for col in df.columns if col not in categorical_cols + ignore_cols]\n",
        "\n",
        "# Encode categorical\n",
        "df['Gender'] = LabelEncoder().fit_transform(df['Gender'])\n",
        "\n",
        "# Scale numericals\n",
        "scaler = StandardScaler()\n",
        "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
        "\n",
        "# Split\n",
        "X = df[categorical_cols + numerical_cols]\n",
        "y = df[target]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "73d97f02",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73d97f02",
        "outputId": "d1a1d72b-1af6-4f4f-d8ff-ff44f8d29f00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss = 26.5336\n",
            "Epoch 2: Loss = 8.4288\n",
            "Epoch 3: Loss = 7.5323\n",
            "Epoch 4: Loss = 6.2093\n",
            "Epoch 5: Loss = 5.8302\n",
            "Epoch 6: Loss = 5.4447\n",
            "Epoch 7: Loss = 4.8590\n",
            "Epoch 8: Loss = 4.5968\n",
            "Epoch 9: Loss = 4.1327\n",
            "Epoch 10: Loss = 3.8597\n"
          ]
        }
      ],
      "source": [
        "# Split into categorical and continuous\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "X_categ_train = torch.tensor(X_train.iloc[:, 0].values, dtype=torch.long).unsqueeze(1).to(device)\n",
        "X_cont_train = torch.tensor(X_train.iloc[:, 1:].values, dtype=torch.float32).to(device)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1).to(device)\n",
        "\n",
        "X_categ_test = torch.tensor(X_test.iloc[:, 0].values, dtype=torch.long).unsqueeze(1).to(device)\n",
        "X_cont_test = torch.tensor(X_test.iloc[:, 1:].values, dtype=torch.float32).to(device)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1).to(device)\n",
        "\n",
        "# Model\n",
        "model = TabTransformer(\n",
        "    categories=(2,),\n",
        "    num_continuous=X_train.shape[1] - 1,\n",
        "    dim=64,\n",
        "    dim_out=1,\n",
        "    depth=4,\n",
        "    heads=4,\n",
        "    attn_dropout=0.1,\n",
        "    ff_dropout=0.1\n",
        ").to(device)\n",
        "\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch import nn\n",
        "\n",
        "train_dataset = TensorDataset(X_categ_train, X_cont_train, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# Train TabTransformer\n",
        "model.train()\n",
        "for epoch in range(10):\n",
        "    total_loss = 0\n",
        "    for x_cat, x_cont, yb in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(x_cat, x_cont)\n",
        "        loss = loss_fn(preds, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}: Loss = {total_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5307215e",
      "metadata": {
        "id": "5307215e"
      },
      "outputs": [],
      "source": [
        "# ElasticNet\n",
        "elastic_model = ElasticNet()\n",
        "elastic_model.fit(X_train, y_train)\n",
        "joblib.dump(elastic_model, \"elastic_model.pkl\")\n",
        "\n",
        "# CatBoost\n",
        "catboost_model = CatBoostRegressor(verbose=0)\n",
        "catboost_model.fit(X_train, y_train)\n",
        "catboost_model.save_model(\"catboost_model.cbm\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "5eebd60b",
      "metadata": {
        "id": "5eebd60b"
      },
      "outputs": [],
      "source": [
        "class TorchTabTransformerWrapper(BaseEstimator, RegressorMixin):\n",
        "    def __init__(self, model, device='cpu'):\n",
        "        self.model = model.to(device)\n",
        "        self.device = device\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # Already trained externally â€” no action needed\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Expecting X to be a DataFrame with categorical in col 0, rest numeric\n",
        "        x_categ = torch.tensor(X.iloc[:, 0].values, dtype=torch.long).unsqueeze(1).to(self.device)\n",
        "        x_cont = torch.tensor(X.iloc[:, 1:].values, dtype=torch.float32).to(self.device)\n",
        "\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            preds = self.model(x_categ, x_cont)\n",
        "        return preds.cpu().numpy().flatten()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Manual Ensemble Logic\n",
        "\n",
        "# predictions from all base models\n",
        "cat_preds = catboost_model.predict(X_test)\n",
        "elastic_preds = elastic_model.predict(X_test)\n",
        "tab_preds = TorchTabTransformerWrapper(model, device=device).predict(X_test)\n",
        "\n",
        "# Stack predictions as features for meta-model\n",
        "import numpy as np\n",
        "meta_X = np.vstack([cat_preds, elastic_preds, tab_preds]).T\n",
        "meta_y = y_test\n",
        "\n",
        "# Train meta-model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "meta_model = LinearRegression()\n",
        "meta_model.fit(meta_X, meta_y)\n",
        "\n",
        "# Final ensemble prediction\n",
        "stack_preds = meta_model.predict(meta_X)\n",
        "\n",
        "# Evaluate\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "mae = mean_absolute_error(meta_y, stack_preds)\n",
        "rmse = np.sqrt(mean_squared_error(meta_y, stack_preds))\n",
        "r2 = r2_score(meta_y, stack_preds)\n",
        "\n",
        "print(f\"\\nğŸ“Š Manual Stacked Ensemble Results:\")\n",
        "print(f\"MAE:  {mae:.4f}\")\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"RÂ²:   {r2:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-L4OFqAmKlQ",
        "outputId": "3cf83f63-5fd8-47d2-89c9-2a5488fa7189"
      },
      "id": "p-L4OFqAmKlQ",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“Š Manual Stacked Ensemble Results:\n",
            "MAE:  0.0512\n",
            "RMSE: 0.0717\n",
            "RÂ²:   0.9947\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}